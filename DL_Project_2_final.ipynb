{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KLHT8IHASH6S"
      },
      "outputs": [],
      "source": [
        "# Importing PyTorch, the foundational deep learning framework used for model training and inference.\n",
        "import torch\n",
        "\n",
        "# Importing components from Hugging Face's 'transformers' library:\n",
        "from transformers import (\n",
        "    # Tokenizer for the RoBERTa model — used to convert text into tokens for the model.\n",
        "    RobertaTokenizer,\n",
        "    # Pretrained RoBERTa model specifically configured for sequence classification tasks.\n",
        "    RobertaForSequenceClassification,\n",
        "    # Automatically pads tokenized inputs to the maximum sequence length in a batch.\n",
        "    DataCollatorWithPadding,\n",
        "    # Holds the training configuration settings like learning rate, batch size, number of epochs, etc.\n",
        "    TrainingArguments,\n",
        "    # High-level class to manage the training and evaluation loop.\n",
        "    Trainer,\n",
        "    # Allows early stopping of training if the model performance stops improving.\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "\n",
        "# Importing components from 'peft' — Parameter-Efficient Fine-Tuning library.\n",
        "# This allows fine-tuning of large models efficiently by training fewer parameters.\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# Hugging Face's 'datasets' library:\n",
        "# - load_dataset is used to load datasets from Hugging Face Hub or custom datasets.\n",
        "# - Dataset class allows manual creation or manipulation of datasets.\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Accuracy metric from scikit-learn to evaluate classification performance.\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# NumPy is a fundamental package for numerical operations in Python.\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG986lhN0CW0"
      },
      "source": [
        "This block brings in all the essential libraries for the deep learning pipeline you're about to construct:\n",
        "\n",
        "- **torch**: Core deep learning operations like tensor computations and backpropagation are handled here.\n",
        "\n",
        "- **transformers**: This library gives you easy access to pretrained models like RoBERTa and handles all NLP-related tokenization, training utilities, and evaluation mechanisms.\n",
        "\n",
        "- **peft (Parameter-Efficient Fine-Tuning)**: Enables a lightweight and efficient way to fine-tune large transformer models. This is crucial when computational resources are limited.\n",
        "\n",
        "- **datasets**: A streamlined way to load and preprocess datasets.\n",
        "\n",
        "- **sklearn.metrics**: Used here to compute accuracy, which is a common metric for classification tasks.\n",
        "\n",
        "- **numpy**: Helps in mathematical operations, especially useful for metrics computation and data manipulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HtP0IsmA13P",
        "outputId": "eb2891df-989d-42fc-9ef7-47580cd8b84e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 704,260 || all params: 125,352,968 || trainable%: 0.5618\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer and model\n",
        "# Define the pretrained model to use — \"roberta-base\" is a popular transformer model trained on a large corpus.\n",
        "model_name = \"roberta-base\"\n",
        "# Load the tokenizer associated with RoBERTa — responsible for converting raw text into token IDs.\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "# Load the RoBERTa model specifically configured for classification with 4 output labels (i.e., 4 classes).\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
        "\n",
        "\n",
        "# Freeze base model parameters (we'll only train LoRA + classifier)\n",
        "# Freezing all parameters of the base RoBERTa model to prevent them from being updated during training.\n",
        "# This is done because we want to use LoRA for efficient fine-tuning.\n",
        "for param in model.roberta.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Define which modules inside the transformer will be fine-tuned using LoRA — usually attention components.\n",
        "target_modules = [\"query\", \"key\", \"value\"]\n",
        "\n",
        "# Create a LoRA configuration:\n",
        "lora_config=LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,  # Apply LoRA to a sequence classification task\n",
        "    r=2,                         # Rank of the low‑rank decomposition (controls parameter count)\n",
        "    lora_alpha=4,                # Scaling factor for the LoRA weight updates\n",
        "    lora_dropout=0.1,            # Dropout applied within the LoRA layers for regularization\n",
        "    bias=\"none\",                 # Don’t fine‑tune any bias terms\n",
        "    target_modules=target_modules  # List of module names (e.g., [\"query\",\"key\",\"value\"]) to inject LoRA into\n",
        ")\n",
        "\n",
        "# Inject LoRA into the model based on the configuration.\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Optional: check trainable params\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hNCvgxj0Wlt"
      },
      "source": [
        "### Model and Tokenizer Initialization\n",
        "\n",
        "- Loads the `roberta-base` tokenizer and model for sequence classification with 4 labels (for the AG News dataset).\n",
        "\n",
        "### Freezing Base Model\n",
        "\n",
        "- Freezes all parameters of the base RoBERTa model to ensure only the LoRA layers and classifier are trained.\n",
        "\n",
        "### LoRA Configuration\n",
        "\n",
        "Configures LoRA (Low-Rank Adaptation) with the following settings:\n",
        "\n",
        "- `task_type=TaskType.SEQ_CLS`: Specifies you're fine‑tuning for a sequence classification problem.\n",
        "- `r=2`: Chooses a very small rank (2) for the additional LoRA matrices, ensuring minimal extra parameters.\n",
        "- `lora_alpha=4`: Scales the LoRA updates by 4, which can help stabilize training and improve convergence.\n",
        "- `lora_dropout=0.1`: Adds 10% dropout inside LoRA layers to prevent overfitting on small datasets.\n",
        "- `bias=\"none\"`: Keeps all original bias parameters frozen; only the LoRA weights (and model head) are trainable.\n",
        "- `target_modules=target_modules`: You typically pass `[\"query\", \"key\", \"value\"]` so LoRA only modifies the attention mechanism, preserving the rest of the pretrained model.\n",
        "\n",
        "### Trainable Parameters\n",
        "\n",
        "- Prints the number of trainable parameters (0.56% of total parameters), showing the efficiency of LoRA.\n",
        "\n",
        "> Some weights of `RobertaForSequenceClassification` were not initialized...\n",
        "\n",
        "- `trainable params: 704,260 || all params: 125,352,968 || trainable%: 0.5618`\n",
        "\n",
        "A warning about newly initialized classifier layers is expected since the model is being fine-tuned.\n",
        "\n",
        "Only 0.56% of the total parameters are trainable, demonstrating LoRA's parameter efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5BVQtZZVSOa",
        "outputId": "fc2267c1-e74a-46e0-e410-8148056662b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PeftModelForSequenceClassification(\n",
            "  (base_model): LoraModel(\n",
            "    (model): RobertaForSequenceClassification(\n",
            "      (roberta): RobertaModel(\n",
            "        (embeddings): RobertaEmbeddings(\n",
            "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "          (token_type_embeddings): Embedding(1, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): RobertaEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0-11): 12 x RobertaLayer(\n",
            "              (attention): RobertaAttention(\n",
            "                (self): RobertaSdpaSelfAttention(\n",
            "                  (query): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=2, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=2, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (key): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=2, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=2, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (value): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=768, out_features=2, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=2, out_features=768, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): RobertaIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): RobertaOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (classifier): ModulesToSaveWrapper(\n",
            "        (original_module): RobertaClassificationHead(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
            "        )\n",
            "        (modules_to_save): ModuleDict(\n",
            "          (default): RobertaClassificationHead(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oFIf7VEOBGyi"
      },
      "outputs": [],
      "source": [
        "# Tokenization function\n",
        "def preprocess_function(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=True, max_length=256)\n",
        "\n",
        "# Load and preprocess dataset\n",
        "raw_dataset = load_dataset(\"ag_news\", split=\"train\")\n",
        "tokenized_dataset = raw_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Split dataset into train/validation\n",
        "splits = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = splits[\"train\"]\n",
        "eval_dataset = splits[\"test\"]\n",
        "\n",
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ND_-7gH2NoY"
      },
      "source": [
        "### Tokenization Function\n",
        "\n",
        "- Tokenizes text using the tokenizer with:\n",
        "  - Truncation\n",
        "  - Padding to a maximum length of 256 tokens\n",
        "\n",
        "### Dataset Loading\n",
        "\n",
        "- Loads the **AG News** dataset using the `datasets` library.\n",
        "- Applies the tokenization function to all examples.\n",
        "- Renames the `label` column to `labels` for compatibility with Hugging Face's training APIs.\n",
        "\n",
        "### Train-Validation Split\n",
        "\n",
        "- Splits the dataset into:\n",
        "  - 90% for training\n",
        "  - 10% for validation\n",
        "\n",
        "### Data Collator\n",
        "\n",
        "- Uses a data collator that dynamically pads each batch to the longest sequence in that batch.\n",
        "- Improves efficiency by avoiding padding all sequences to the max length globally.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mWcgB7t9BXct"
      },
      "outputs": [],
      "source": [
        "# Define a custom metric function used during evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    # Extract logits (raw model outputs) and ground-truth labels\n",
        "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "    # Convert logits to predicted class indices by selecting the one with the highest score\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    # Compute and return accuracy between predictions and actual labels\n",
        "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_lora\",  # Directory for model checkpoints and logs\n",
        "    eval_strategy=\"epoch\",  # Evaluate after each epoch\n",
        "    save_strategy=\"epoch\",  # Save model after each epoch\n",
        "    learning_rate=4e-6,  # Low LR for fine-tuning\n",
        "    per_device_train_batch_size=32,  # Training batch size\n",
        "    per_device_eval_batch_size=64,  # Evaluation batch size\n",
        "    num_train_epochs=3,  # Number of training epochs\n",
        "    weight_decay=0.003,  # L2 regularization\n",
        "    load_best_model_at_end=True,  # Load best model at end\n",
        "    metric_for_best_model=\"eval_accuracy\",  # Use accuracy for model selection\n",
        "    greater_is_better=True,  # Higher accuracy is better\n",
        "    logging_steps=100,  # Log every 100 steps\n",
        "    optim=\"adamw_torch\",  # Optimizer\n",
        "    push_to_hub=False,  # Don't push to HF Hub\n",
        "    fp16=True,  # Mixed precision training\n",
        "    report_to=None  # Disable external logging\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veJ68wcO2Ubm"
      },
      "source": [
        "### Metrics Function\n",
        "\n",
        "- Defines a function to compute **accuracy** during evaluation using `sklearn.metrics`.\n",
        "\n",
        "### Training Arguments\n",
        "\n",
        "Configures the training setup with the following:\n",
        "\n",
        "- **Learning rate**: `4e-6`\n",
        "- **Batch sizes**:\n",
        "  - Training batch size: `32`\n",
        "  - Evaluation batch size: `64`\n",
        "- **Epochs**: `3`\n",
        "- **Weight decay**: Applied for regularization to reduce overfitting\n",
        "- **Model checkpointing**: Saves the **best model** based on validation accuracy\n",
        "- **Mixed precision (fp16)**: Enabled for faster training on compatible GPUs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS-KHC1sBbU5",
        "outputId": "5538a08c-0c12-42dc-d0c0-bf4fe830eab0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,  # The model to train/evaluate\n",
        "    args=training_args,  # The training arguments (configured above)\n",
        "    train_dataset=train_dataset,  # The training dataset\n",
        "    eval_dataset=eval_dataset,  # The evaluation dataset\n",
        "    data_collator=data_collator,  # Function to collate data batches\n",
        "    compute_metrics=compute_metrics,  # Metrics function for evaluation\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Stop training early if no improvement\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCQ__O-y2YyD"
      },
      "source": [
        "### Trainer Setup\n",
        "\n",
        "The `Trainer` is initialized with the following components:\n",
        "\n",
        "- **model**: The LoRA-adapted model you've prepared for training.\n",
        "- **args**: The training configuration defined using `TrainingArguments`.\n",
        "- **train_dataset** & **eval_dataset**: Datasets for training and validation, respectively.\n",
        "- **data_collator**: Handles dynamic padding within each batch, improving memory efficiency when dealing with sequences of varying lengths.\n",
        "- **compute_metrics**: A custom function that computes **accuracy** during evaluation.\n",
        "- **callbacks**: Includes `EarlyStoppingCallback` to stop training early if validation accuracy doesn't improve for 3 consecutive evaluations (`early_stopping_patience=3`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "3FaZEUyeBd7E",
        "outputId": "a402b4fa-053d-43e5-c410-9ec2e4e15500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10125' max='10125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10125/10125 13:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.320600</td>\n",
              "      <td>0.304649</td>\n",
              "      <td>0.896667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.330300</td>\n",
              "      <td>0.291020</td>\n",
              "      <td>0.900417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.312100</td>\n",
              "      <td>0.287946</td>\n",
              "      <td>0.901333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10125, training_loss=0.3537936629307123, metrics={'train_runtime': 819.6001, 'train_samples_per_second': 395.315, 'train_steps_per_second': 12.354, 'total_flos': 4.2975241224192e+16, 'train_loss': 0.3537936629307123, 'epoch': 3.0})"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train\n",
        "print(\"Starting training...\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "H4GRKogRBvrk",
        "outputId": "337e5581-2b8f-4e87-95fd-ed25cd0fde78"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 00:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.9013\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Validation accuracy: {eval_results['eval_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "25f063ad222948c5affd5374d77d7612",
            "751113f3e3fc4fd3a6183bfb45e221e1",
            "6b3785274a2b49f181994acb39ace5ec",
            "f34e47b5f8a7428f89097434da733be3",
            "e790e9959e4f4e29bead7608dec398bc",
            "9024d78e2ae24a06b6c5c47f4058a305",
            "bc6092f249b24a1888712dae7697ed6f",
            "9622dc35556d40148d566f5ee9347007",
            "5c148c56ddbe4cdfada5d1c64ed79e37",
            "a356d34afad14afba1c9a93ea9bcd91e",
            "d3e4e8d9519349958fc3b02da9fe0a5c"
          ]
        },
        "id": "2mj_kkEAH3Y8",
        "outputId": "7a2b9137-2a2f-4a0c-98aa-9480cccfcb32"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load unlabeled test data\n",
        "unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
        "# If it's a pandas DataFrame, convert to Hugging Face Dataset for easy batch processing\n",
        "if isinstance(unlabelled_dataset, pd.DataFrame):\n",
        "    test_dataset = Dataset.from_pandas(unlabelled_dataset)\n",
        "else:\n",
        "    test_dataset = unlabelled_dataset  # already a Dataset\n",
        "\n",
        "# Preprocess the test dataset (tokenize)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# Run inference in batches\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(axis=-1)\n",
        "\n",
        "# Prepare submission dataframe\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": range(len(pred_labels)),\n",
        "    \"Label\": pred_labels\n",
        "})\n",
        "# Save to CSV (no index, just two columns)\n",
        "submission.to_csv(\"Fsub_proj2_12.csv\", index=False)\n",
        "print(f\"Predictions saved to local system\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z7pk9zZdnZ6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25f063ad222948c5affd5374d77d7612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_751113f3e3fc4fd3a6183bfb45e221e1",
              "IPY_MODEL_6b3785274a2b49f181994acb39ace5ec",
              "IPY_MODEL_f34e47b5f8a7428f89097434da733be3"
            ],
            "layout": "IPY_MODEL_e790e9959e4f4e29bead7608dec398bc"
          }
        },
        "5c148c56ddbe4cdfada5d1c64ed79e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b3785274a2b49f181994acb39ace5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9622dc35556d40148d566f5ee9347007",
            "max": 8000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c148c56ddbe4cdfada5d1c64ed79e37",
            "value": 8000
          }
        },
        "751113f3e3fc4fd3a6183bfb45e221e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9024d78e2ae24a06b6c5c47f4058a305",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6092f249b24a1888712dae7697ed6f",
            "value": "Map: 100%"
          }
        },
        "9024d78e2ae24a06b6c5c47f4058a305": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9622dc35556d40148d566f5ee9347007": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a356d34afad14afba1c9a93ea9bcd91e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6092f249b24a1888712dae7697ed6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e4e8d9519349958fc3b02da9fe0a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e790e9959e4f4e29bead7608dec398bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34e47b5f8a7428f89097434da733be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a356d34afad14afba1c9a93ea9bcd91e",
            "placeholder": "​",
            "style": "IPY_MODEL_d3e4e8d9519349958fc3b02da9fe0a5c",
            "value": " 8000/8000 [00:05&lt;00:00, 1503.55 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
